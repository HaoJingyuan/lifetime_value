{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 当成多分类问题解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped unique values: [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10), np.int64(11), np.int64(12), np.int64(13), np.int64(14), np.int64(15), np.int64(16), np.int64(17), np.int64(18), np.int64(19), np.int64(20), np.int64(21), np.int64(22), np.int64(23), np.int64(24), np.int64(25), np.int64(26), np.int64(27), np.int64(28), np.int64(29), np.int64(30), np.int64(31), np.int64(32), np.int64(33), np.int64(34), np.int64(35), np.int64(36), np.int64(37), np.int64(38), np.int64(39), np.int64(40), np.int64(41), np.int64(42), np.int64(43), np.int64(44), np.int64(45), np.int64(46), np.int64(47), np.int64(48), np.int64(49), np.int64(50), np.int64(51), np.int64(52), np.int64(53), np.int64(54), np.int64(55), np.int64(56), np.int64(57), np.int64(58), np.int64(59), np.int64(60), np.int64(61), np.int64(62), np.int64(63), np.int64(64), np.int64(65), np.int64(66), np.int64(67), np.int64(68), np.int64(69), np.int64(70), np.int64(71), np.int64(72), np.int64(73), np.int64(74), np.int64(75), np.int64(76), np.int64(77), np.int64(78), np.int64(79), np.int64(80), np.int64(81), np.int64(82), np.int64(83), np.int64(84), np.int64(85), np.int64(86), np.int64(87), np.int64(88), np.int64(89), np.int64(90), np.int64(91), np.int64(92), np.int64(93), np.int64(94), np.int64(95), np.int64(96), np.int64(97), np.int64(98), np.int64(99), np.int64(100), np.int64(101), np.int64(102), np.int64(103), np.int64(104), np.int64(105), np.int64(106), np.int64(107), np.int64(108), np.int64(109), np.int64(110), np.int64(111), np.int64(112), np.int64(113), np.int64(114), np.int64(115), np.int64(116), np.int64(117), np.int64(118), np.int64(119), np.int64(120), np.int64(121), np.int64(122), np.int64(123), np.int64(124), np.int64(125), np.int64(126), np.int64(127), np.int64(128), np.int64(129), np.int64(130), np.int64(131), np.int64(132), np.int64(133), np.int64(134), np.int64(135), np.int64(136), np.int64(137), np.int64(138), np.int64(139), np.int64(140), np.int64(141), np.int64(142), np.int64(143), np.int64(144), np.int64(145), np.int64(146), np.int64(147), np.int64(148), np.int64(149), np.int64(150), np.int64(151), np.int64(152), np.int64(153), np.int64(154), np.int64(155), np.int64(156), np.int64(157), np.int64(158), np.int64(159), np.int64(160), np.int64(161), np.int64(162), np.int64(163), np.int64(164), np.int64(165), np.int64(166), np.int64(167), np.int64(168), np.int64(169), np.int64(170), np.int64(171), np.int64(172), np.int64(173), np.int64(174), np.int64(175), np.int64(176), np.int64(177), np.int64(178), np.int64(179), np.int64(180), np.int64(181), np.int64(182), np.int64(183), np.int64(184), np.int64(185), np.int64(186), np.int64(187), np.int64(188), np.int64(189), np.int64(190), np.int64(191), np.int64(192), np.int64(193), np.int64(194), np.int64(195), np.int64(196), np.int64(197), np.int64(198), np.int64(199), np.int64(200), np.int64(201), np.int64(202), np.int64(203), np.int64(204)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# 示例数据\n",
    "df  = pd.read_csv('D:\\github_repo_forked\\lifetime_value\\kuaidian\\clean\\sliding_window_data_expanded.csv')\n",
    "\n",
    "# 过滤掉样本数少于2的类别\n",
    "min_samples = 5  # 每个类别最少样本数\n",
    "class_counts = df['next_chapter'].value_counts()\n",
    "valid_classes = class_counts[class_counts >= min_samples].index\n",
    "df = df[df['next_chapter'].isin(valid_classes)]\n",
    "\n",
    "# 编码分类特征\n",
    "categorical_features = ['os_version', 'device_brand', 'loc_city_id']\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_features = encoder.fit_transform(df[categorical_features])\n",
    "\n",
    "# 将编码后的特征转换为DataFrame\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(categorical_features))\n",
    "\n",
    "# 删除原始的分类特征列\n",
    "df.drop(columns=categorical_features, inplace=True)\n",
    "\n",
    "# 将编码后的特征与原始数据合并\n",
    "df = pd.concat([df, encoded_df], axis=1)\n",
    "\n",
    "# 分离特征和目标变量\n",
    "\n",
    "X = df.drop(columns=['next_chapter','user_id'])\n",
    "y = df['next_chapter']\n",
    "\n",
    "# 1. 重新映射类别\n",
    "unique_chapters = sorted(df['next_chapter'].unique())\n",
    "chapter_to_idx = {chapter: idx for idx, chapter in enumerate(unique_chapters)}\n",
    "idx_to_chapter = {idx: chapter for idx, chapter in enumerate(unique_chapters)}\n",
    "\n",
    "# 3. 验证映射是否连续\n",
    "y = df['next_chapter'].map(chapter_to_idx)\n",
    "print(\"Mapped unique values:\", sorted(y.unique()))\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y ,random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 创建并训练模型\n",
    "model = XGBClassifier(objective='multi:softmax', num_class=len(y.unique()), use_label_encoder=False, eval_metric='mlogloss')\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 进行预测\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 评估模型\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "Best score: 0.6395368072787427\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "model = XGBClassifier(objective='multi:softmax')\n",
    "\n",
    "# 创建 GridSearchCV 对象\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='accuracy')\n",
    "\n",
    "# 在训练集上进行网格搜索\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 输出最佳参数和最佳得分\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jingyuan.hao\\AppData\\Local\\anaconda3\\envs\\ziln\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [19:07:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "optimal_model = XGBClassifier(\n",
    "    max_depth=3,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    subsample=0.8,\n",
    "    objective='multi:softmax', \n",
    "    num_class=len(y.unique()), \n",
    "    use_label_encoder=False, \n",
    "    eval_metric='mlogloss'\n",
    ")\n",
    "optimal_model.fit(X_train, y_train)\n",
    "y_pred = optimal_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  混淆矩阵热力图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 假设 y_test 是真实标签，y_pred 是预测标签\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 分类报告可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ClassificationReport\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 创建分类器\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 创建可视化对象\n",
    "visualizer = ClassificationReport(model, support=True)\n",
    "visualizer.fit(X_train, y_train)\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  ROC曲线（针对多分类）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikitplot as skplt\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# 二值化标签\n",
    "y_test_bin = label_binarize(y_test, classes=range(len(np.unique(y))))\n",
    "y_probas = model.predict_proba(X_test)\n",
    "\n",
    "# 绘制ROC曲线\n",
    "skplt.metrics.plot_roc(y_test_bin, y_probas)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "类别总数: 391\n",
      "\n",
      "样本数分布:\n",
      "count    391.000000\n",
      "mean      19.406650\n",
      "std       57.336263\n",
      "min        1.000000\n",
      "25%        3.000000\n",
      "50%        5.000000\n",
      "75%       11.000000\n",
      "max      547.000000\n",
      "Name: count, dtype: float64\n",
      "单样本类别数量: 59\n"
     ]
    }
   ],
   "source": [
    "class_counts = df['next_chapter'].value_counts()\n",
    "print(f\"类别总数: {len(class_counts)}\")\n",
    "print(\"\\n样本数分布:\")\n",
    "print(class_counts.describe())\n",
    "single_sample_classes = class_counts[class_counts == 1]\n",
    "\n",
    "print(f\"单样本类别数量: {len(single_sample_classes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "过滤后的类别数: 332\n",
      "过滤后的样本数: 7529\n"
     ]
    }
   ],
   "source": [
    "min_samples = 2  # 每个类别最少样本数\n",
    "valid_classes = class_counts[class_counts >= min_samples].index\n",
    "filtered_df = df[df['next_chapter'].isin(valid_classes)]\n",
    "\n",
    "print(f\"\\n过滤后的类别数: {len(valid_classes)}\")\n",
    "print(f\"过滤后的样本数: {len(filtered_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 当成回归问题解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 3594.53\n",
      "Mean Absolute Error (MAE): 27.06\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "df  = pd.read_csv('D:\\github_repo_forked\\lifetime_value\\kuaidian\\clean\\sliding_window_data_expanded.csv')\n",
    "\n",
    "\n",
    "# 编码分类特征\n",
    "categorical_features = ['os_version', 'device_brand', 'loc_city_id']\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_features = encoder.fit_transform(df[categorical_features])\n",
    "\n",
    "# 将编码后的特征转换为DataFrame\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(categorical_features))\n",
    "\n",
    "# 删除原始的分类特征列\n",
    "df.drop(columns=categorical_features, inplace=True)\n",
    "\n",
    "# 将编码后的特征与原始数据合并\n",
    "df = pd.concat([df, encoded_df], axis=1)\n",
    "\n",
    "# 分离特征和目标变量\n",
    "X = df.drop(columns=['next_chapter','user_id'])\n",
    "y = df['next_chapter']\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建并训练模型\n",
    "model = XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 进行预测\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 评估模型\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error (MSE): {mse:.2f}')\n",
    "print(f'Mean Absolute Error (MAE): {mae:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ziln",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
